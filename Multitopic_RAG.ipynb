{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download Libraries & Ollama"
      ],
      "metadata": {
        "id": "6Z68MpvnRUhN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO8-nFcISWoY",
        "outputId": "4b82e2b2-7627-48ba-989c-54048b85d55e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Downloading ollama...\n",
            "############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU pinecone-client pinecone-datasets langchain-pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5_tBuXKxIyC",
        "outputId": "1d8d5b4d-c796-458e-d8b1-3af0d0929591"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.9/215.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet langchain_community tiktoken langchainhub langchain langgraph langchain-mistralai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBoD-HXLxKsE",
        "outputId": "fed8b507-b3c0-43b5-c32c-e69a6b9ba1b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "botocore 1.31.17 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CUvWSiOxRyP",
        "outputId": "f06e6e8b-d933-4f5e-f203-cde18e9497a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Libraries"
      ],
      "metadata": {
        "id": "G3ujyPzGRYcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import bs4\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import pinecone\n",
        "from pinecone import Pinecone, ServerlessSpec, PodSpec\n",
        "from langchain_community.document_loaders import WikipediaLoader\n",
        "from google.colab import userdata\n",
        "import time\n",
        "from langchain import hub\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.utils.math import cosine_similarity"
      ],
      "metadata": {
        "id": "PixUkvxRxUHf"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up langsmith & Pinecone APIs"
      ],
      "metadata": {
        "id": "pwmjSiN9RbeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "# In the following two lines either replace the function with\n",
        "# your API keys or save them in the secrets section in google\n",
        "# colab\n",
        "os.environ['LANGCHAIN_API_KEY'] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ['PINECONE_API_KEY'] = userdata.get('PINECONE_API_KEY')\n",
        "pinecone_api_key = os.environ['PINECONE_API_KEY']\n",
        "use_serverless = True"
      ],
      "metadata": {
        "id": "Mtxz1-TyxZzX"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Docs"
      ],
      "metadata": {
        "id": "HG_oc3KWRgsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aero_docs = WikipediaLoader(query=\"Aeronautics\", lang=\"en\", load_max_docs=1).load()\n",
        "aero_docs.extend(WikipediaLoader(query=\"Aerospace engineering\", lang=\"en\", load_max_docs=1).load())\n",
        "aero_docs.extend(WikipediaLoader(query=\"Avionics\", lang=\"en\", load_max_docs=1).load())\n",
        "aero_docs.extend(WikipediaLoader(query=\"Flight dynamics\", lang=\"en\", load_max_docs=1).load())\n",
        "aero_docs.extend(WikipediaLoader(query=\"Aircraft design process\", lang=\"en\", load_max_docs=1).load())\n",
        "aero_docs.extend(WikipediaLoader(query=\"Aircraft flight control system\", lang=\"en\", load_max_docs=1).load())\n",
        "aero_docs.extend(WikipediaLoader(query=\"Aircraft flight mechanics\", lang=\"en\", load_max_docs=1).load())"
      ],
      "metadata": {
        "id": "VzRtY6ydxqXG"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naval_docs = WikipediaLoader(query=\"Naval architecture\", lang=\"en\", load_max_docs=1).load()\n",
        "naval_docs.extend(WikipediaLoader(query=\"Ship stability\", lang=\"en\", load_max_docs=1).load())\n",
        "naval_docs.extend(WikipediaLoader(query=\"Hydraulic engineering\", lang=\"en\", load_max_docs=1).load())\n",
        "naval_docs.extend(WikipediaLoader(query=\"Flight dynamics\", lang=\"en\", load_max_docs=1).load())\n",
        "naval_docs.extend(WikipediaLoader(query=\"Fluid dynamics\", lang=\"en\", load_max_docs=1).load())\n",
        "naval_docs.extend(WikipediaLoader(query=\"Hydrostatics\", lang=\"en\", load_max_docs=1).load())\n",
        "naval_docs.extend(WikipediaLoader(query=\"Marine engineering\", lang=\"en\", load_max_docs=1).load())"
      ],
      "metadata": {
        "id": "3Xpeniphz22B"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Chunking"
      ],
      "metadata": {
        "id": "vojXXoSnRixh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def doc_chunk(docs, chunk_size= 5000, chunk_overlap= 500):\n",
        "  # Split\n",
        "  text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "      chunk_size = chunk_size,\n",
        "      chunk_overlap = chunk_overlap)\n",
        "\n",
        "  # Make splits\n",
        "  splits = text_splitter.split_documents(docs)\n",
        "  return splits"
      ],
      "metadata": {
        "id": "TqjvB0Ut0gd2"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_naval_splits = doc_chunk(naval_docs)\n",
        "summary_aero_splits = doc_chunk(aero_docs)"
      ],
      "metadata": {
        "id": "qi_VDbDN0uZr"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_naval_splits = doc_chunk(naval_docs, chunk_size=500, chunk_overlap=50)\n",
        "retrieval_aero_splits = doc_chunk(aero_docs, chunk_size=500, chunk_overlap=50)"
      ],
      "metadata": {
        "id": "9BgX9BH_0_Xz"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(summary_naval_splits[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "AXv2HJAl9mBg",
        "outputId": "881e26f5-46dc-4322-94f9-0aba39d4a5fb"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.documents.base.Document"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.documents.base.Document</b><br/>def __init__(page_content: str, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_core/documents/base.py</a>Class for storing a piece of text and associated metadata.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 9);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarizing documents"
      ],
      "metadata": {
        "id": "k6C0Ya17RlzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_split_summary(split, llm):\n",
        "  prompt = \"\"\"\n",
        "  Give me a summary of the following document in 500 tokens:\n",
        "  {document}\n",
        "  \"\"\"\n",
        "  prompt_template = PromptTemplate(\n",
        "      input_variables = [\"document\"],\n",
        "      template = prompt\n",
        "  )\n",
        "\n",
        "  summarize_chain = prompt_template | llm | StrOutputParser()\n",
        "  summary = summarize_chain.invoke({\"document\": split.page_content})\n",
        "  summary = \":\".join(summary.split(\":\")[1:])\n",
        "  summary_doc = Document(page_content=summary, metadata=split.metadata)\n",
        "  return summary_doc"
      ],
      "metadata": {
        "id": "RdpWpVJw1TTR"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_local_llm = \"llama3\"\n",
        "\n",
        "summary_llm = ChatOllama(model=summary_local_llm, temperature=0.75)"
      ],
      "metadata": {
        "id": "rv0_m5uc-kDH"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_all_splits(summary_naval_splits, summary_aero_splits, llm):\n",
        "  aero_summary_docs = []\n",
        "  naval_summary_docs = []\n",
        "  for split in summary_naval_splits:\n",
        "    summary_doc = get_split_summary(split, llm)\n",
        "    naval_summary_docs.append(summary_doc)\n",
        "  for split in summary_aero_splits:\n",
        "    summary_doc = get_split_summary(split, llm)\n",
        "    aero_summary_docs.append(summary_doc)\n",
        "  return aero_summary_docs, naval_summary_docs"
      ],
      "metadata": {
        "id": "YZ8PWwEU_8lr"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aero_summary_docs, naval_summary_docs = summarize_all_splits(summary_naval_splits, summary_aero_splits, summary_llm)"
      ],
      "metadata": {
        "id": "wKMsiodfAuFT"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_all_docs(docs, llm):\n",
        "  combined_doc = \"\\n\".join([doc.page_content for doc in docs])\n",
        "  prompt = \"\"\"\n",
        "  Give me a summary of the following document in 500 tokens:\n",
        "  # {combined_doc}\n",
        "  \"\"\"\n",
        "  prompt_template = PromptTemplate(\n",
        "      input_variables = [\"combined_doc\"],\n",
        "      template = prompt\n",
        "  )\n",
        "\n",
        "  summarize_chain = prompt_template | llm | StrOutputParser()\n",
        "  summary = summarize_chain.invoke({\"combined_doc\": combined_doc})\n",
        "  summary = \":\".join(summary.split(\":\")[1:])\n",
        "  summary_doc = Document(page_content=summary)\n",
        "  return summary_doc"
      ],
      "metadata": {
        "id": "DAtMCKzjDpF4"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aero_summary = summarize_all_docs(aero_summary_docs, summary_llm)\n",
        "naval_summary = summarize_all_docs(naval_summary_docs, summary_llm)"
      ],
      "metadata": {
        "id": "W4esxrqUEtFb"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(aero_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "7iRUyn6vJwTm",
        "outputId": "98598a0f-b7ed-49f9-a94b-e1da733c67b0"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.documents.base.Document"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.documents.base.Document</b><br/>def __init__(page_content: str, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_core/documents/base.py</a>Class for storing a piece of text and associated metadata.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 9);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding summaries to the chunks"
      ],
      "metadata": {
        "id": "xX5G4VZjRrcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_naval_splits = retrieval_naval_splits + naval_summary_docs\n",
        "retrieval_naval_splits.append(naval_summary)\n",
        "retrieval_aero_splits = retrieval_aero_splits + aero_summary_docs\n",
        "retrieval_aero_splits.append(aero_summary)"
      ],
      "metadata": {
        "id": "l1PVkU51Ey2K"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the embeddings"
      ],
      "metadata": {
        "id": "UHWYDMtPRwtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")"
      ],
      "metadata": {
        "id": "X0kSgVu2H-2E"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings.embed_query(\"hello world\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg7QVn7YMm2Y",
        "outputId": "bc672df9-dd55-4ef9-e868-7a658d4473d4"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Pinecone dbs"
      ],
      "metadata": {
        "id": "24xnT0ZDR3Y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "def create_pinecone_index(pc, index_name, embedding_dim = 1024, use_serverless = True, metric = \"dotproduct\"):\n",
        "    if use_serverless:\n",
        "        spec = ServerlessSpec(cloud='aws', region='us-west-2')\n",
        "    else:\n",
        "        # if not using a starter index, you should specify a pod_type too\n",
        "        spec = PodSpec()\n",
        "    # check for and delete index if already exists\n",
        "    if index_name in pc.list_indexes().names():\n",
        "        pc.delete_index(index_name)\n",
        "    # create a new index\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension= embedding_dim,  # dimensionality of the embedding model\n",
        "        metric= metric,\n",
        "        spec=spec\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    while not pc.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)"
      ],
      "metadata": {
        "id": "1etuMPkgMrB_"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_pinecone_index(pc, \"aero-db\")\n",
        "create_pinecone_index(pc, \"naval-db\")"
      ],
      "metadata": {
        "id": "kem782QNMvyC"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "def create_pinecone_vectorstore(splits, embeddings, index_name):\n",
        "  vectorstore = Pinecone.from_documents(splits, embeddings, index_name = index_name)\n",
        "  retriever = vectorstore.as_retriever()\n",
        "  return vectorstore, retriever"
      ],
      "metadata": {
        "id": "eOBn1y2PM60J"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aero_vectorstore, aero_retriever = create_pinecone_vectorstore(retrieval_aero_splits, embeddings, \"aero-db\")\n",
        "naval_vectorstore, naval_retriever = create_pinecone_vectorstore(retrieval_naval_splits, embeddings, \"naval-db\")"
      ],
      "metadata": {
        "id": "dT9j9iggNBrl"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantinc Router"
      ],
      "metadata": {
        "id": "VT2442HlR64r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = [aero_summary, naval_summary]\n",
        "summary_names = [\"aero\", \"naval\"]\n",
        "summary_embeddings = embeddings.embed_documents(summaries)"
      ],
      "metadata": {
        "id": "MJjQ7AUcGb-y"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_router(query):\n",
        "    # Embed question\n",
        "    query_embedding = embeddings.embed_query(query)\n",
        "    # Compute similarity\n",
        "    similarity = cosine_similarity([query_embedding], summary_embeddings)[0]\n",
        "    most_similar = summary_names[similarity.argmax()]\n",
        "    return most_similar\n",
        "\n",
        "def query_retriever(query, most_similar):\n",
        "    if most_similar == \"aero\":\n",
        "        return aero_retriever.get_relevant_documents(query)\n",
        "    else:\n",
        "        return naval_retriever.get_relevant_documents(query)"
      ],
      "metadata": {
        "id": "UPEHnoe5M-8R"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG with LLaMA3"
      ],
      "metadata": {
        "id": "QNddaXr3QkPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the fundamental concept of fluid mechanics\"\n",
        "route = query_router(question)\n",
        "retrieved_docs = query_retriever(question, route)\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "rag_chain = prompt | summary_llm | StrOutputParser()\n",
        "result = rag_chain.invoke({\"context\": retrieved_docs, \"question\": question})"
      ],
      "metadata": {
        "id": "JP1MceqKP9ue"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iUVQb_LCQVXl",
        "outputId": "7e8032da-ab47-4c77-ee09-580e50667bd3"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The foundational axioms of fluid dynamics are the conservation laws specifically'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG with Mistral"
      ],
      "metadata": {
        "id": "Fh52XpXnQqXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local_llm = \"mistral:latest\"\n",
        "\n",
        "llm = ChatOllama(model=local_llm, temperature=0.75)"
      ],
      "metadata": {
        "id": "5Jlt4SxAQ2L4"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the fundamental concept of fluid mechanics\"\n",
        "route = query_router(question)\n",
        "retrieved_docs = query_retriever(question, route)\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "rag_chain = prompt | llm | StrOutputParser()\n",
        "result = rag_chain.invoke({\"context\": retrieved_docs, \"question\": question})"
      ],
      "metadata": {
        "id": "x7qTXcWhQqFT"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "RLwSu-2MRGrd",
        "outputId": "d14464f5-576b-440f-a22d-2cfe44982a9c"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Fluid dynamics is a subdiscipline of fluid mechanics that describes the flow of liquids and gases. It has several applications, including calculating forces and moments on aircraft, determining mass flow rates in pipelines, predicting weather patterns, understanding nebulae in interstellar space, and modeling fission weapon detonation. The foundational axioms of fluid dynamics are the conservation laws for mass, linear momentum, and energy. Fluids are assumed to obey the continuum assumption, which assumes fluids are continuous rather than discrete. For Newtonian fluids, the momentum equations are described by the Navier-Stokes equations, which do not have a general closed-form solution and are primarily used in computational fluid dynamics. A thermodynamic equation of state is also required to describe the problem completely. For example, the perfect gas equation of state relates pressure, density, temperature, molar mass, and gas constant. Additionally, a constitutive relation may be useful.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    }
  ]
}
